{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배경\n",
    "\n",
    "Open-Domain Question Answering (ODQA) 문제의 해결을 위한 연구는 모델 파라미터와 별개로 외부 corpus에 접근할 수 있는지 여부에 따라 Open-Book 모델과 Closed-Book 모델로 구분될 수 있습니다(Roberts et al., 2020). Open-Book 모델 중 Lewis et al.(2020)의 RAG 모델은 질문에 답변하기 위하여 인공신경망이 참조할 수 있는 외부 corpus를 검색하는 retrieval과, 찾아낸 corpus를 참조하여 답변을 생성하는 generator을 결합하여 주목할만한 결과를 얻었습니다. RAG는 retrieval과 generator로 각각 DPR(Karpukhin et al., 2020)과 BART(Lewis et al., 2020)을 사용하였습니다.\n",
    "\n",
    "본 주피터 노트북은 HuggingFace NLP course를 공부한 내용을 정리하기 위해 retriever와 generator를 결합한 RAG의 방식을 차용하여 Question Answering을 연습해본 기록입니다. HuggingFace 웹페이지에서 제공하는 코드들을 응용하여 작성해보았습니다. 다만 기본적인 형태를 연습하는 과정에서 BERT의 embedding space를 사용한 RAG 모델과는 달리 retriever로 MPNet Embedding Space를 활용하여 Semantic Search를 수행하였고, generator로는 HuggingFace Transformer에서 기본적으로 제공하는 text2text-generation pipeline 및 eli5 dataset에 대하여 fine-tuning된 BART 모델을 사용하였습니다. 시간관계 상, 그리고 gpu 사양의 한계로 본 노트북에서 따로 fine-tuning을 수행하지는 않았습니다. 추후에는 특정 분야에 대한 전문적인 corpus를 대상으로 finetuning을 진행해보고자 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래와 같은 라이브러리 설치가 필요합니다. faiss-gpu의 경우 Linux 기준 pip를 통해 설치할 수 있으나 저는 윈도우에서 작업하여 conda를 사용하였습니다.\n",
    "# 윈도우 기준 conda를 통해 faiss-gpu를 설치한 경우는 커널을 재시작해주어야 정상작동하는 모습을 보였습니다. \n",
    "\n",
    "# !pip pytorch datasets evaluate transformers[sentencepiece]\n",
    "# conda install -c conda-forge faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # requirements\n",
    "\n",
    "# pytorch\n",
    "# datasets\n",
    "# evaluate\n",
    "# transformers[sentencepiece]\n",
    "\n",
    "# # conda install -c conda-forge faiss-gpu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Dataset**\n",
    "\n",
    "Question과 Answer 그리고 Context가 모두 주어진 데이터셋을 사용하고자 하였고, SQuAD를 선택하였습니다.\\\n",
    "노트북의 하단에서는 eli5 데이터셋을 사용하여 동일한 작업을 수행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\23_05_RAG\\RAG\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset squad (C:/Users/user/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQuAD 데이터셋을 불러옵니다.\n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_dataset = load_dataset(\"squad\", split=\"train\")\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\user\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\\cache-10de9997c4b83f65.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'answers'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤으로 N개의 샘플을 선택합니다. 본 노트북에서는 따로 Training을 수행하지는 않으며\n",
    "# N개의 sample만을 대상으로 semantic search와 generation task를 수행하였습니다. \n",
    "N = 1000\n",
    "sample_dataset = raw_dataset.shuffle(seed=42).select(range(N)).select_columns(['question', 'answers', 'context'])\n",
    "sample_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'The Pew Forum on Religion & Public Life ranks Egypt as the fifth worst country in the world for religious freedom. The United States Commission on International Religious Freedom, a bipartisan independent agency of the US government, has placed Egypt on its watch list of countries that require close monitoring due to the nature and extent of violations of religious freedom engaged in or tolerated by the government. According to a 2010 Pew Global Attitudes survey, 84% of Egyptians polled supported the death penalty for those who leave Islam; 77% supported whippings and cutting off of hands for theft and robbery; and 82% support stoning a person who commits adultery.',\n",
       " 'question': 'What percentage of Egyptians polled support death penalty for those leaving Islam?',\n",
       " 'answers': {'text': ['84%'], 'answer_start': [468]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retrieval** (Semantic Search with FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MPNet을 불러와 tokenizer와 embedding 모델로 사용합니다.\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "mpnet_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "mpnet_tokenizer = AutoTokenizer.from_pretrained(mpnet_ckpt)\n",
    "retriever = AutoModel.from_pretrained(mpnet_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPNetModel(\n",
       "  (embeddings): MPNetEmbeddings(\n",
       "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): MPNetEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (relative_attention_bias): Embedding(32, 12)\n",
       "  )\n",
       "  (pooler): MPNetPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "retriever.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu 메모리 관리를 위한 함수\n",
    "import gc\n",
    "\n",
    "def clean():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러온 모델을 활용해 input에 대한 embedding을 얻는 함수를 작성합니다.\n",
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:, 0]\n",
    "\n",
    "def get_embeddings(text_list, model):\n",
    "    encoded_input = mpnet_tokenizer(\n",
    "        text_list, \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        return_overflowing_tokens=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    result = cls_pooling(model_output).detach().cpu().numpy()[0]\n",
    "    \n",
    "    del encoded_input, model_output\n",
    "    clean()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "# embedding shape preview\n",
    "embedding = get_embeddings(sample_dataset[\"context\"][0], retriever)\n",
    "print(embedding.shape)\n",
    "del embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\user\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\\cache-041716c3067efe4e.arrow\n",
      "100%|██████████| 1/1 [00:00<00:00, 167.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'answers', 'embeddings'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map 함수를 사용해 dataset의 모든 context에 대한 embedding을 얻습니다. 이후 faiss index를 추가합니다.\n",
    "embeddings_dataset = sample_dataset.map(\n",
    "    lambda x: {\"embeddings\": get_embeddings(x[\"context\"], retriever)}\n",
    ")\n",
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장과 불러오기를 위한 구간\n",
    "import pickle\n",
    "\n",
    "with open(file='embeddings_dataset_squad_{}.pickle'.format(N), mode='wb') as f:\n",
    "    pickle.dump(embeddings_dataset, f)\n",
    "    \n",
    "# with open(file='embeddings_dataset_squad_{}.pickle'.format(N), mode='rb') as f:\n",
    "#     embeddings_dataset=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  The energy used for metabolism of the brain in humans is what percentage?\n",
      "A:  20–25%\n"
     ]
    }
   ],
   "source": [
    "# N개의 데이터에 대하여 특정 index의 question과 answer를 불러옵니다. 또한 question에 대한 embedding을 얻습니다. \n",
    "idx = 125\n",
    "\n",
    "question = sample_dataset['question'][idx]\n",
    "question_embedding = get_embeddings([question], retriever)\n",
    "question_embedding.shape\n",
    "print('Q: ', question)\n",
    "\n",
    "answer = sample_dataset['answers'][idx]['text'][0]\n",
    "print('A: ', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 얻은 question embedding이 context embedding과 갖는 유사도를 계산하여 가장 유사한 k개의 sample을 얻습니다.\n",
    "scores, samples = embeddings_dataset.get_nearest_examples(\n",
    "    \"embeddings\", question_embedding, k=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brain tissue consumes a large amount of energy...</td>\n",
       "      <td>The energy used for metabolism of the brain in...</td>\n",
       "      <td>{'text': ['20–25%'], 'answer_start': [559]}</td>\n",
       "      <td>[0.32254528999328613, -0.4942903518676758, -0....</td>\n",
       "      <td>29.692329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Some types of energy are a varying mix of both...</td>\n",
       "      <td>What is dependent upon electrical potential en...</td>\n",
       "      <td>{'text': ['Elastic energy in materials'], 'ans...</td>\n",
       "      <td>[0.1286253184080124, -0.27638325095176697, -0....</td>\n",
       "      <td>45.315144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Early recommendations for the quantity of wate...</td>\n",
       "      <td>How much water should be taken in for each cal...</td>\n",
       "      <td>{'text': ['1 milliliter'], 'answer_start': [469]}</td>\n",
       "      <td>[0.23622414469718933, -0.18039996922016144, -0...</td>\n",
       "      <td>47.218964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bacteria are further divided into lithotrophs ...</td>\n",
       "      <td>What do respiratory organisms use as electron ...</td>\n",
       "      <td>{'text': ['chemical compounds'], 'answer_start...</td>\n",
       "      <td>[0.10745195299386978, -0.362464964389801, -0.1...</td>\n",
       "      <td>48.950485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Efficiency of a transmitting antenna is the ra...</td>\n",
       "      <td>What can cause that reaction?</td>\n",
       "      <td>{'text': ['transmitter'], 'answer_start': [494]}</td>\n",
       "      <td>[-0.09236371517181396, -0.733789324760437, -0....</td>\n",
       "      <td>48.979622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Only a few contemporary societies are classifi...</td>\n",
       "      <td>Besides  agriculture, how do gatherers add to ...</td>\n",
       "      <td>{'text': ['keeping animals'], 'answer_start': ...</td>\n",
       "      <td>[-0.30304154753685, 0.40761739015579224, -0.19...</td>\n",
       "      <td>49.569466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dietary fiber is a carbohydrate that is incomp...</td>\n",
       "      <td>What is an example of a gastrointestinal probl...</td>\n",
       "      <td>{'text': ['constipation'], 'answer_start': [771]}</td>\n",
       "      <td>[-0.07349792867898941, 0.10766194015741348, -0...</td>\n",
       "      <td>49.936504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The judges continue in paragraph 12, \"The dete...</td>\n",
       "      <td>The number of people targeted in a genocide sh...</td>\n",
       "      <td>{'text': ['absolute terms'], 'answer_start': [...</td>\n",
       "      <td>[0.22658081352710724, -0.41311776638031006, -0...</td>\n",
       "      <td>50.440056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Spanish is currently the most widely taught no...</td>\n",
       "      <td>What other languages are popular among America...</td>\n",
       "      <td>{'text': ['French (14.4%), German (7.1%), Ital...</td>\n",
       "      <td>[-0.18415644764900208, -0.2967764437198639, -0...</td>\n",
       "      <td>50.696846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bacterial growth follows four phases. When a p...</td>\n",
       "      <td>What is called the third statge of growth of b...</td>\n",
       "      <td>{'text': ['stationary phase'], 'answer_start':...</td>\n",
       "      <td>[0.23717251420021057, -0.4525332450866699, -0....</td>\n",
       "      <td>50.884193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context   \n",
       "0  Brain tissue consumes a large amount of energy...  \\\n",
       "1  Some types of energy are a varying mix of both...   \n",
       "2  Early recommendations for the quantity of wate...   \n",
       "3  Bacteria are further divided into lithotrophs ...   \n",
       "4  Efficiency of a transmitting antenna is the ra...   \n",
       "5  Only a few contemporary societies are classifi...   \n",
       "6  Dietary fiber is a carbohydrate that is incomp...   \n",
       "7  The judges continue in paragraph 12, \"The dete...   \n",
       "8  Spanish is currently the most widely taught no...   \n",
       "9  Bacterial growth follows four phases. When a p...   \n",
       "\n",
       "                                            question   \n",
       "0  The energy used for metabolism of the brain in...  \\\n",
       "1  What is dependent upon electrical potential en...   \n",
       "2  How much water should be taken in for each cal...   \n",
       "3  What do respiratory organisms use as electron ...   \n",
       "4                      What can cause that reaction?   \n",
       "5  Besides  agriculture, how do gatherers add to ...   \n",
       "6  What is an example of a gastrointestinal probl...   \n",
       "7  The number of people targeted in a genocide sh...   \n",
       "8  What other languages are popular among America...   \n",
       "9  What is called the third statge of growth of b...   \n",
       "\n",
       "                                             answers   \n",
       "0        {'text': ['20–25%'], 'answer_start': [559]}  \\\n",
       "1  {'text': ['Elastic energy in materials'], 'ans...   \n",
       "2  {'text': ['1 milliliter'], 'answer_start': [469]}   \n",
       "3  {'text': ['chemical compounds'], 'answer_start...   \n",
       "4   {'text': ['transmitter'], 'answer_start': [494]}   \n",
       "5  {'text': ['keeping animals'], 'answer_start': ...   \n",
       "6  {'text': ['constipation'], 'answer_start': [771]}   \n",
       "7  {'text': ['absolute terms'], 'answer_start': [...   \n",
       "8  {'text': ['French (14.4%), German (7.1%), Ital...   \n",
       "9  {'text': ['stationary phase'], 'answer_start':...   \n",
       "\n",
       "                                          embeddings     scores  \n",
       "0  [0.32254528999328613, -0.4942903518676758, -0....  29.692329  \n",
       "1  [0.1286253184080124, -0.27638325095176697, -0....  45.315144  \n",
       "2  [0.23622414469718933, -0.18039996922016144, -0...  47.218964  \n",
       "3  [0.10745195299386978, -0.362464964389801, -0.1...  48.950485  \n",
       "4  [-0.09236371517181396, -0.733789324760437, -0....  48.979622  \n",
       "5  [-0.30304154753685, 0.40761739015579224, -0.19...  49.569466  \n",
       "6  [-0.07349792867898941, 0.10766194015741348, -0...  49.936504  \n",
       "7  [0.22658081352710724, -0.41311776638031006, -0...  50.440056  \n",
       "8  [-0.18415644764900208, -0.2967764437198639, -0...  50.696846  \n",
       "9  [0.23717251420021057, -0.4525332450866699, -0....  50.884193  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas로 시각화\n",
    "import pandas as pd\n",
    "\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=True, inplace=True)\n",
    "\n",
    "samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Brain tissue consumes a large amount of energy in proportion to its volume, so large brains place severe metabolic demands on animals. The need to limit body weight in order, for example, to fly, has apparently led to selection for a reduction of brain size in some species, such as bats. Most of the brain's energy consumption goes into sustaining the electric charge (membrane potential) of neurons. Most vertebrate species devote between 2% and 8% of basal metabolism to the brain. In primates, however, the percentage is much higher—in humans it rises to 20–25%. The energy consumption of the brain does not vary greatly over time, but active regions of the cerebral cortex consume somewhat more energy than inactive regions; this forms the basis for the functional brain imaging methods PET, fMRI, and NIRS. The brain typically gets most of its energy from oxygen-dependent metabolism of glucose (i.e., blood sugar), but ketones provide a major alternative source, together with contributions from medium chain fatty acids (caprylic and heptanoic acids), lactate, acetate, and possibly amino acids.\",\n",
       " 'Some types of energy are a varying mix of both potential and kinetic energy. An example is mechanical energy which is the sum of (usually macroscopic) kinetic and potential energy in a system. Elastic energy in materials is also dependent upon electrical potential energy (among atoms and molecules), as is chemical energy, which is stored and released from a reservoir of electrical potential energy between electrons, and the molecules or atomic nuclei that attract them.[need quotation to verify].The list is also not necessarily complete. Whenever physical scientists discover that a certain phenomenon appears to violate the law of energy conservation, new forms are typically added that account for the discrepancy.',\n",
       " 'Early recommendations for the quantity of water required for maintenance of good health suggested that 6–8 glasses of water daily is the minimum to maintain proper hydration. However the notion that a person should consume eight glasses of water per day cannot be traced to a credible scientific source. The original water intake recommendation in 1945 by the Food and Nutrition Board of the National Research Council read: \"An ordinary standard for diverse persons is 1 milliliter for each calorie of food. Most of this quantity is contained in prepared foods.\" More recent comparisons of well-known recommendations on fluid intake have revealed large discrepancies in the volumes of water we need to consume for good health. Therefore, to help standardize guidelines, recommendations for water consumption are included in two recent European Food Safety Authority (EFSA) documents (2010): (i) Food-based dietary guidelines and (ii) Dietary reference values for water or adequate daily intakes (ADI). These specifications were provided by calculating adequate intakes from measured intakes in populations of individuals with “desirable osmolarity values of urine and desirable water volumes per energy unit consumed.” For healthful hydration, the current EFSA guidelines recommend total water intakes of 2.0 L/day for adult females and 2.5 L/day for adult males. These reference values include water from drinking water, other beverages, and from food. About 80% of our daily water requirement comes from the beverages we drink, with the remaining 20% coming from food. Water content varies depending on the type of food consumed, with fruit and vegetables containing more than cereals, for example. These values are estimated using country-specific food balance sheets published by the Food and Agriculture Organisation of the United Nations. Other guidelines for nutrition also have implications for the beverages we consume for healthy hydration- for example, the World Health Organization (WHO) recommend that added sugars should represent no more than 10% of total energy intake.',\n",
       " 'Bacteria are further divided into lithotrophs that use inorganic electron donors and organotrophs that use organic compounds as electron donors. Chemotrophic organisms use the respective electron donors for energy conservation (by aerobic/anaerobic respiration or fermentation) and biosynthetic reactions (e.g., carbon dioxide fixation), whereas phototrophic organisms use them only for biosynthetic purposes. Respiratory organisms use chemical compounds as a source of energy by taking electrons from the reduced substrate and transferring them to a terminal electron acceptor in a redox reaction. This reaction releases energy that can be used to synthesise ATP and drive metabolism. In aerobic organisms, oxygen is used as the electron acceptor. In anaerobic organisms other inorganic compounds, such as nitrate, sulfate or carbon dioxide are used as electron acceptors. This leads to the ecologically important processes of denitrification, sulfate reduction, and acetogenesis, respectively.',\n",
       " \"Efficiency of a transmitting antenna is the ratio of power actually radiated (in all directions) to the power absorbed by the antenna terminals. The power supplied to the antenna terminals which is not radiated is converted into heat. This is usually through loss resistance in the antenna's conductors, but can also be due to dielectric or magnetic core losses in antennas (or antenna systems) using such components. Such loss effectively robs power from the transmitter, requiring a stronger transmitter in order to transmit a signal of a given strength.\",\n",
       " 'Only a few contemporary societies are classified as hunter-gatherers, and many supplement their foraging activity with horticulture and/or keeping animals.',\n",
       " 'Dietary fiber is a carbohydrate that is incompletely absorbed in humans and in some animals. Like all carbohydrates, when it is metabolized it can produce four Calories (kilocalories) of energy per gram. However, in most circumstances it accounts for less than that because of its limited absorption and digestibility. Dietary fiber consists mainly of cellulose, a large carbohydrate polymer which is indigestible as humans do not have the required enzymes to disassemble it. There are two subcategories: soluble and insoluble fiber. Whole grains, fruits (especially plums, prunes, and figs), and vegetables are good sources of dietary fiber. There are many health benefits of a high-fiber diet. Dietary fiber helps reduce the chance of gastrointestinal problems such as constipation and diarrhea by increasing the weight and size of stool and softening it. Insoluble fiber, found in whole wheat flour, nuts and vegetables, especially stimulates peristalsis – the rhythmic muscular contractions of the intestines, which move digesta along the digestive tract. Soluble fiber, found in oats, peas, beans, and many fruits, dissolves in water in the intestinal tract to produce a gel that slows the movement of food through the intestines. This may help lower blood glucose levels because it can slow the absorption of sugar. Additionally, fiber, perhaps especially that from whole grains, is thought to possibly help lessen insulin spikes, and therefore reduce the risk of type 2 diabetes. The link between increased fiber consumption and a decreased risk of colorectal cancer is still uncertain.',\n",
       " 'The judges continue in paragraph 12, \"The determination of when the targeted part is substantial enough to meet this requirement may involve a number of considerations. The numeric size of the targeted part of the group is the necessary and important starting point, though not in all cases the ending point of the inquiry. The number of individuals targeted should be evaluated not only in absolute terms, but also in relation to the overall size of the entire group. In addition to the numeric size of the targeted portion, its prominence within the group can be a useful consideration. If a specific part of the group is emblematic of the overall group, or is essential to its survival, that may support a finding that the part qualifies as substantial within the meaning of Article 4 [of the Tribunal\\'s Statute].\"',\n",
       " 'Spanish is currently the most widely taught non-English language in American secondary schools and of higher education. More than 1.4 million university students were enrolled in language courses in autumn of 2002 and Spanish is the most widely taught language in American colleges and universities with 53 percent of the total number of people enrolled, followed by French (14.4%), German (7.1%), Italian (4.5%), American Sign language (4.3%), Japanese (3.7%), and Chinese (2.4%) although the totals remain relatively small in relation to the total U.S population.',\n",
       " 'Bacterial growth follows four phases. When a population of bacteria first enter a high-nutrient environment that allows growth, the cells need to adapt to their new environment. The first phase of growth is the lag phase, a period of slow growth when the cells are adapting to the high-nutrient environment and preparing for fast growth. The lag phase has high biosynthesis rates, as proteins necessary for rapid growth are produced. The second phase of growth is the log phase, also known as the logarithmic or exponential phase. The log phase is marked by rapid exponential growth. The rate at which cells grow during this phase is known as the growth rate (k), and the time it takes the cells to double is known as the generation time (g). During log phase, nutrients are metabolised at maximum speed until one of the nutrients is depleted and starts limiting growth. The third phase of growth is the stationary phase and is caused by depleted nutrients. The cells reduce their metabolic activity and consume non-essential cellular proteins. The stationary phase is a transition from rapid growth to a stress response state and there is increased expression of genes involved in DNA repair, antioxidant metabolism and nutrient transport. The final phase is the death phase where the bacteria run out of nutrients and die.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 찾아낸 k개의 context들을 유사도가 높은 것부터 결합하여 list로 반환합니다.\n",
    "samples_df['context'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 list 원소들을 문자열로 변환하고 결합합니다. 이것이 질문과 함께 제공되는 우리의 external corpus (context)가 됩니다. \n",
    "context = str()\n",
    "for sentence in samples_df['context'].to_list():\n",
    "    context += sentence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generator**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HuggingFace Transformer에서 제공하는 \"text2text-generation\" pipeline을 generator로 사용하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\user\\Documents\\23_05_RAG\\RAG\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text2text_generator = pipeline(\"text2text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2143 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The energy used for metabolism of the brain in humans is what percentage?\n",
      "20–25%\n",
      "20–25%\n"
     ]
    }
   ],
   "source": [
    "# 차례대로 주어진 질문, 모델이 뱉어낸 답변 및 정답입니다.\n",
    "print(question)\n",
    "output = text2text_generator(\"question: {} context: {}\".format(question, context))\n",
    "print(output[0]['generated_text'])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2% to 8%\n"
     ]
    }
   ],
   "source": [
    "# 질문에 대해 찾아낸 context와 관련하여 다른 질문을 던져보았습니다. 적절히 대답하는 모습을 보여줍니다.\n",
    "question2 = 'how much energy does fly use for metabolism of the brain?'\n",
    "output = text2text_generator(\"question: {} context: {}\".format(question2, context))\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **eli5 dataset with BART Generator**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 eli5 데이터셋을 사용하여 같은 방식을 적용하되, BART를 Generator로 사용하고자합니다.\\\n",
    "https://yjernite.github.io/lfqa.html#dense_use의 코드를 참조하였으며,\\\n",
    "사용한 BART 모델 역시 해당 링크에서 eli5 데이터셋에 대하여 fine-tuning을 진행한 모델입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset eli5 (C:/Users/user/.cache/huggingface/datasets/eli5/LFQA_reddit/1.0.0/17574e5502a10f41bbd17beba83e22475b499fa62caa1384a3d093fc856fe6fa)\n"
     ]
    }
   ],
   "source": [
    "# eli5 데이터셋을 불러옵니다. 과학을 주제로 하는 'asks' split을 사용하고자합니다. \n",
    "raw_dataset = load_dataset(\"eli5\", split=\"train_asks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\user\\.cache\\huggingface\\datasets\\eli5\\LFQA_reddit\\1.0.0\\17574e5502a10f41bbd17beba83e22475b499fa62caa1384a3d093fc856fe6fa\\cache-5c2bb45099cb5c79.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마찬가지로 1000개의 sample을 뽑아 사용합니다. title과 answer를 각각 question과 context로 변경하여 사용할 것입니다. \n",
    "N = 1000\n",
    "sample_dataset = raw_dataset.shuffle(seed=42).select(range(N)).select_columns(['title', 'answers'])\n",
    "sample_dataset = sample_dataset.rename_column('title', 'question')\n",
    "sample_dataset = sample_dataset.rename_column('answers', 'context')\n",
    "sample_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are there any equivalents to logical gates in ...</td>\n",
       "      <td>{'a_id': ['c7ni94z', 'c7nil06'], 'text': ['Neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you eat the same thing everyday, does your ...</td>\n",
       "      <td>{'a_id': ['cerowjh'], 'text': ['There is a ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Statistically speaking, how far away should th...</td>\n",
       "      <td>{'a_id': ['ccgb84o'], 'text': ['The [nearest b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geologists  &amp;  Geology enthusiasts: What could...</td>\n",
       "      <td>{'a_id': ['cawg229'], 'text': ['Before I say a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can scattering of blue light simultaneousl...</td>\n",
       "      <td>{'a_id': ['cskd9um', 'cskf4c7'], 'text': ['Day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Where do autistic people derive their of moral...</td>\n",
       "      <td>{'a_id': ['c6qj8wu', 'c6qn82j', 'c6qmj1r', 'c6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>How can we know things like how many people \"d...</td>\n",
       "      <td>{'a_id': ['dzx1btj'], 'text': ['We can only kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>What would happen to an eye completely bereft ...</td>\n",
       "      <td>{'a_id': ['cp7g3f4'], 'text': ['In case anyone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Big Bang and the accelerating universe?</td>\n",
       "      <td>{'a_id': ['ckbywpd', 'ckbzu38'], 'text': ['In ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>If we were to cut a person in half with a blad...</td>\n",
       "      <td>{'a_id': ['c3v20g9'], 'text': ['You appear to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question   \n",
       "0    Are there any equivalents to logical gates in ...  \\\n",
       "1    If you eat the same thing everyday, does your ...   \n",
       "2    Statistically speaking, how far away should th...   \n",
       "3    Geologists  &  Geology enthusiasts: What could...   \n",
       "4    How can scattering of blue light simultaneousl...   \n",
       "..                                                 ...   \n",
       "995  Where do autistic people derive their of moral...   \n",
       "996  How can we know things like how many people \"d...   \n",
       "997  What would happen to an eye completely bereft ...   \n",
       "998            Big Bang and the accelerating universe?   \n",
       "999  If we were to cut a person in half with a blad...   \n",
       "\n",
       "                                               context  \n",
       "0    {'a_id': ['c7ni94z', 'c7nil06'], 'text': ['Neu...  \n",
       "1    {'a_id': ['cerowjh'], 'text': ['There is a ver...  \n",
       "2    {'a_id': ['ccgb84o'], 'text': ['The [nearest b...  \n",
       "3    {'a_id': ['cawg229'], 'text': ['Before I say a...  \n",
       "4    {'a_id': ['cskd9um', 'cskf4c7'], 'text': ['Day...  \n",
       "..                                                 ...  \n",
       "995  {'a_id': ['c6qj8wu', 'c6qn82j', 'c6qmj1r', 'c6...  \n",
       "996  {'a_id': ['dzx1btj'], 'text': ['We can only kn...  \n",
       "997  {'a_id': ['cp7g3f4'], 'text': ['In case anyone...  \n",
       "998  {'a_id': ['ckbywpd', 'ckbzu38'], 'text': ['In ...  \n",
       "999  {'a_id': ['c3v20g9'], 'text': ['You appear to ...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context에 답변의 id가 포함되어있습니다. 이를 무시하고 답변 내용인 text만 사용하고자합니다. \n",
    "sample_dataset.set_format(\"pandas\")\n",
    "sample_df = sample_dataset[:]\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are there any equivalents to logical gates in ...</td>\n",
       "      <td>Neurons  function similar way as logic gates i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are there any equivalents to logical gates in ...</td>\n",
       "      <td>Heh.  We wish we had found such a thing.\\n\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you eat the same thing everyday, does your ...</td>\n",
       "      <td>There is a very substantial variation among th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Statistically speaking, how far away should th...</td>\n",
       "      <td>The [nearest brown dwarf](_URL_0_) -- a pair o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geologists  &amp;  Geology enthusiasts: What could...</td>\n",
       "      <td>Before I say anything stupid, is there any cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question   \n",
       "0  Are there any equivalents to logical gates in ...  \\\n",
       "1  Are there any equivalents to logical gates in ...   \n",
       "2  If you eat the same thing everyday, does your ...   \n",
       "3  Statistically speaking, how far away should th...   \n",
       "4  Geologists  &  Geology enthusiasts: What could...   \n",
       "\n",
       "                                             context  \n",
       "0  Neurons  function similar way as logic gates i...  \n",
       "1  Heh.  We wish we had found such a thing.\\n\\nTh...  \n",
       "2  There is a very substantial variation among th...  \n",
       "3  The [nearest brown dwarf](_URL_0_) -- a pair o...  \n",
       "4  Before I say anything stupid, is there any cha...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply와 lambda 함수를 사용해 답변의 text만을 context로 사용합니다. \n",
    "sample_df['context'] = sample_df['context'].apply(lambda x: x['text'])\n",
    "\n",
    "# 하나의 질문에 대해 여러 답변이 달린 경우를 explode 함수를 사용해 분리해줍니다.  \n",
    "sample_df = sample_df.explode(\"context\", ignore_index=True)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas 데이터프레임을 다시 dataset으로 변경합니다. \n",
    "from datasets import Dataset\n",
    "\n",
    "sample_dataset = Dataset.from_pandas(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map 함수를 사용해 dataset의 모든 context에 대한 embedding을 얻습니다. 이후 faiss index를 추가합니다.\n",
    "embeddings_dataset = sample_dataset.map(\n",
    "    lambda x: {\"embeddings\": get_embeddings(x[\"context\"], retriever)}\n",
    ")\n",
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")\n",
    "\n",
    "# 저장과 불러오기를 위한 구간\n",
    "with open(file='embeddings_dataset_eli5_{}.pickle'.format(N), mode='wb') as f:\n",
    "    pickle.dump(embeddings_dataset, f)\n",
    "\n",
    "# with open(file='embeddings_dataset_eli5_{}.pickle'.format(N), mode='rb') as f:\n",
    "#     embeddings_dataset=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  Are there any equivalents to logical gates in the nervous system?\n"
     ]
    }
   ],
   "source": [
    "# N개의 데이터에 대하여 특정 index의 question과 answer를 불러옵니다. 또한 question에 대한 embedding을 얻습니다. \n",
    "idx = 0\n",
    "\n",
    "question = sample_dataset['question'][idx]\n",
    "question_embedding = get_embeddings([question], retriever)\n",
    "\n",
    "print('Q: ', question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 얻은 question embedding이 context embedding과 갖는 유사도를 계산하여 가장 유사한 k개의 sample을 얻습니다.\n",
    "scores, samples = embeddings_dataset.get_nearest_examples(\n",
    "    \"embeddings\", question_embedding, k=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are there any equivalents to logical gates in ...</td>\n",
       "      <td>Heh.  We wish we had found such a thing.\\n\\nTh...</td>\n",
       "      <td>[-0.06319624185562134, -0.027759850025177002, ...</td>\n",
       "      <td>24.671970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is there any legitimacy to \"neuro training\" si...</td>\n",
       "      <td>[Here](_URL_0_) you go. This should answer you...</td>\n",
       "      <td>[-0.1310725212097168, -0.41311880946159363, -0...</td>\n",
       "      <td>37.346756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why is the bond length and angle of phosphorus...</td>\n",
       "      <td>This sounds a lot like a homework question to ...</td>\n",
       "      <td>[-0.228667214512825, -0.20940203964710236, -0....</td>\n",
       "      <td>39.054783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you could get to the centre of a black hole...</td>\n",
       "      <td>[Here](_URL_0_) is RobotRollCall's comment on ...</td>\n",
       "      <td>[-0.117356076836586, -0.3746531009674072, -0.3...</td>\n",
       "      <td>39.055691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What everyday problems could possibly be solve...</td>\n",
       "      <td>This is an incredibly vague question. If you h...</td>\n",
       "      <td>[-0.29924556612968445, -0.27476516366004944, -...</td>\n",
       "      <td>39.088982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How can scattering of blue light simultaneousl...</td>\n",
       "      <td>Walter Lewin demonstrates it (and much more!) ...</td>\n",
       "      <td>[-0.31137293577194214, -0.6795521378517151, -0...</td>\n",
       "      <td>39.189892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Where do autistic people derive their of moral...</td>\n",
       "      <td>This might help a bit. \\n\\nThe Neurobiology of...</td>\n",
       "      <td>[-0.19906999170780182, -0.0950225293636322, -0...</td>\n",
       "      <td>39.694599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Are there any equivalents to logical gates in ...</td>\n",
       "      <td>Neurons  function similar way as logic gates i...</td>\n",
       "      <td>[0.4118035137653351, -0.5458545684814453, 0.08...</td>\n",
       "      <td>39.894703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Is this Russian methane release as ominous as ...</td>\n",
       "      <td>There is already [a discussion](_URL_1_) on th...</td>\n",
       "      <td>[-0.02792995236814022, -0.2829281985759735, -0...</td>\n",
       "      <td>40.497002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Do we perceive time to pass at the same rate i...</td>\n",
       "      <td>Here are a couple of previous threads on the t...</td>\n",
       "      <td>[-0.16528888046741486, -0.3233572244644165, -0...</td>\n",
       "      <td>41.208870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question   \n",
       "0  Are there any equivalents to logical gates in ...  \\\n",
       "1  Is there any legitimacy to \"neuro training\" si...   \n",
       "2  why is the bond length and angle of phosphorus...   \n",
       "3  If you could get to the centre of a black hole...   \n",
       "4  What everyday problems could possibly be solve...   \n",
       "5  How can scattering of blue light simultaneousl...   \n",
       "6  Where do autistic people derive their of moral...   \n",
       "7  Are there any equivalents to logical gates in ...   \n",
       "8  Is this Russian methane release as ominous as ...   \n",
       "9  Do we perceive time to pass at the same rate i...   \n",
       "\n",
       "                                             context   \n",
       "0  Heh.  We wish we had found such a thing.\\n\\nTh...  \\\n",
       "1  [Here](_URL_0_) you go. This should answer you...   \n",
       "2  This sounds a lot like a homework question to ...   \n",
       "3  [Here](_URL_0_) is RobotRollCall's comment on ...   \n",
       "4  This is an incredibly vague question. If you h...   \n",
       "5  Walter Lewin demonstrates it (and much more!) ...   \n",
       "6  This might help a bit. \\n\\nThe Neurobiology of...   \n",
       "7  Neurons  function similar way as logic gates i...   \n",
       "8  There is already [a discussion](_URL_1_) on th...   \n",
       "9  Here are a couple of previous threads on the t...   \n",
       "\n",
       "                                          embeddings     scores  \n",
       "0  [-0.06319624185562134, -0.027759850025177002, ...  24.671970  \n",
       "1  [-0.1310725212097168, -0.41311880946159363, -0...  37.346756  \n",
       "2  [-0.228667214512825, -0.20940203964710236, -0....  39.054783  \n",
       "3  [-0.117356076836586, -0.3746531009674072, -0.3...  39.055691  \n",
       "4  [-0.29924556612968445, -0.27476516366004944, -...  39.088982  \n",
       "5  [-0.31137293577194214, -0.6795521378517151, -0...  39.189892  \n",
       "6  [-0.19906999170780182, -0.0950225293636322, -0...  39.694599  \n",
       "7  [0.4118035137653351, -0.5458545684814453, 0.08...  39.894703  \n",
       "8  [-0.02792995236814022, -0.2829281985759735, -0...  40.497002  \n",
       "9  [-0.16528888046741486, -0.3233572244644165, -0...  41.208870  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas로 시각화\n",
    "import pandas as pd\n",
    "\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=True, inplace=True)\n",
    "\n",
    "samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 찾아낸 k개의 context들을 유사도가 높은 것부터 결합하여 str으로 반환합니다. \n",
    "context = str()\n",
    "for sentence in samples_df['context'].to_list():\n",
    "    context += sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eli5 dataset에 대하여 pre-trained된 모델을 불러옵니다. \n",
    "# https://yjernite.github.io/lfqa.html#dense_use\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "ckpt = \"yjernite/bart_eli5\"\n",
    "bart_tokenizer = AutoTokenizer.from_pretrained(ckpt)\n",
    "bart_model = AutoModelForSeq2SeqLM.from_pretrained(ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 대한 토큰 id와 mask를 가져옵니다. 본 예시에서는 하나의 input을 입력하여 padding을 사용하지 않으므로 attention_mask는 모두 1이 됩니다. \n",
    "q_toks = bart_tokenizer.batch_encode_plus([question], truncation=True)\n",
    "q_ids, q_mask = (\n",
    "    torch.LongTensor(q_toks[\"input_ids\"]).to(device),\n",
    "    torch.LongTensor(q_toks[\"attention_mask\"]).to(device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    0, 13755,    89,   143, 26699,     7, 16437, 14213,    11,     5,\n",
       "           7464,   467,   116,     2]], device='cuda:0'),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰 id, mask의 모습 \n",
    "q_ids, q_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 13755,    89,   143, 26699,     7, 16437, 14213,    11,     5,\n",
       "           7464,   467,   116,     2]], device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model input을 생성합니다. \n",
    "model_inputs = {\n",
    "    \"input_ids\": q_ids,\n",
    "    \"attention_mask\": q_mask\n",
    "}\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 입력을 통해 답변 ids를 생성합니다. \n",
    "generated_ids = bart_model.generate(\n",
    "        input_ids=model_inputs[\"input_ids\"],\n",
    "        attention_mask=model_inputs[\"attention_mask\"],\n",
    "        min_length=60,\n",
    "        max_length=120,\n",
    "        do_sample=False,\n",
    "        early_stopping=True,\n",
    "        num_beams=1,\n",
    "        temperature=1.0,\n",
    "        top_k=None,\n",
    "        top_p=None,\n",
    "        eos_token_id=bart_tokenizer.eos_token_id,\n",
    "        no_repeat_ngram_size=3,\n",
    "        num_return_sequences=1,\n",
    "        decoder_start_token_id=bart_tokenizer.bos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,    20,  7464,   467,    16,    10,   182,  2632,   467,     4,\n",
       "            85,    18,    45,    95,    10,  6900,     9, 21737,     8, 37409,\n",
       "             4,    85,    34,    10,   319,     9,   430,  1667,     4,    20,\n",
       "          7464,  1743,    32,   156,    62,     9,    10,   319,    55,    87,\n",
       "            95,    10,   367, 21737,     8,    10,   367, 37409,     4,    20,\n",
       "         17358,    32,   156,     9,    10,  6900,    55,   383,    87,    95,\n",
       "         21737,     8,     5, 17358,    32,    67,   156,    62,    30,    10,\n",
       "          6900,   114,   383,   101, 14357,     8,  3805,  1790,     4,    20,\n",
       "         10387,    16,   156,    62,  2260,     9,    10,  1086,  6900,     9,\n",
       "           430,   383,     4,    20,  2900,    16,   156,     9,  3739,     9,\n",
       "           430,  6134,     9,   383,     4,    85,    16,   156,  2260,     9,\n",
       "          3739,     8,  3739,     9,   383,    14,    32,   156,    66,     2]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The nervous system is a very complex system. It's not just a bunch of switches and levers. It has a lot of different parts. The nervous systems are made up of a lot more than just a few switches and a few levers. The nerves are made of a bunch more things than just switches and the nerves are also made up by a bunch if things like muscles and tendons. The nerve is made up mostly of a whole bunch of different things. The brain is made of lots of different kinds of things. It is made mostly of lots and lots of things that are made out\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성된 id를 decoding하면 다음과 같은 결과를 볼 수 있습니다. \n",
    "bart_tokenizer.decode(generated_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[question]: Are there any equivalents to logical gates in the nervous system? \n",
      "\n",
      "[context]: Heh.  We wish we had found such a thing.\n",
      "\n",
      "This is a contentious issue, actually.  [Computationalists](_URL_3_) (of which I am one) would say, yes, there have to be... somewhere.  But we don't exactly know where.  [Neural network](_URL_0_) theorists, meanwhile, say that logical gates and computational frameworks are unnecessary; you just need to figure out the strength of connections between different neurons.  They're in love with [LTP](_URL_1_), which they claim backs them up.  And, well, we have actual evidence for LTP.  However, computationalists fire back and say, no, connection strength isn't enough, because then you can't have the brain acting like a Turing machine, which would ultimately be nice for a variety of reasons.  Not in the least, if we're trying to effect a reasonable response to the environment, it would be nice to reconstruct inputs from outputs.  Plus, representations are just so nice to have!  Furthermore, there are a lot of important cognitive problems (say, perception of time, or mental mapping) that seem nigh impossible in a neural network framework but are trivial with computation (which would require logical gates).\n",
      "\n",
      "Basically, we're at an impasse: they've got any evidence at all for what they're saying, but we've got reasons to believe that can't be all there is.  And it's kind of unfortunate.\n",
      "\n",
      "For more, I'd recommend trying to find a copy of [Gallistel and King (2010)](_URL_2_).  It's, er, sometimes readable!  But it talks exactly about this question in ridiculous detail.[Here](_URL_0_) you go. This should answer your question.This sounds a lot like a homework question to be honest. There's /r/HomeworkHelp for that.[Here](_URL_0_) is RobotRollCall's comment on that topic which you might enjoy reading.\n",
      "\n",
      "Also, BH questions come up fairly regularly here, so there is a wealth of knowledge on the topic in the /r/AskScience [search archive](_URL_1_).This is an incredibly vague question. If you have something more specific, I can try to answer.Walter Lewin demonstrates it (and much more!) on his magnificent lecture here: _URL_0_This might help a bit. \n",
      "\n",
      "The Neurobiology of Moral Behavior: Review and Neuropsychiatric Implications\n",
      "\n",
      "_URL_9_Neurons  function similar way as logic gates in computers (in reality they are more complex).  A neuron receives  input signals through its dendrites, then integrates over them and fires if some threshold is reached. Synapses can be inhibitory, excitatory, weak or strong. \n",
      "\n",
      "Some examples of neuron with two two excitatory Inputs:\n",
      "Neuron with two strong excitatory inputs, needs signal from one of the dendrites to fire so it works as  logical or. Neuron with two weak inputs fires only if both inputs are active so it works as logical and.There is already [a discussion](_URL_1_) on this on [/r/askscience](/r/askscience) \n",
      "\n",
      "I think that [things_break's reply to limitnz](_URL_0_) does a good job with this.Here are a couple of previous threads on the topic:\n",
      "\n",
      "_URL_0_\n",
      "\n",
      "_URL_1_\n"
     ]
    }
   ],
   "source": [
    "# context와 비교하여 보면, 모델이 적절한 답변을 생성해내는 것을 확인할 수 있습니다.  \n",
    "print('[question]:', question, '\\n')\n",
    "print('[context]:', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
